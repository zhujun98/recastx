{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"RECASTX","text":"<p>RECASTX (REConstruction of Arbitrary Slabs in Tomography X)  is a GPU-accelerated software written in modern C++(17). This project has been developed based on a successful proof-of-principle test [1] using RECAST3D in 2019 at the TOMCAT, Swiss Light Source. It aims at providing a near real-time streaming data analysis and visualization tool to allow monitoring tomoscopy experiments effectively. It also serves as the foundation of building a smart data acquisition system which has the potential to reduce the recorded data size by removing trivial or repetitive data while preserving the important scientific information which could lead to scientific discoveries.</p> <p>References</p> <p>[1] Buurlage, JW., Marone, F., Pelt, D.M. et al. Real-time reconstruction and visualisation towards dynamic feedback control during time-resolved tomography experiments at TOMCAT. Sci Rep 9, 18379 (2019)</p> <p></p> Get Started Follow Tutorials Learn More Low-latency <p>                 Slab can be defined and reconstructed on-the-fly almost instantly without reconstructing the whole 3D volume.             </p> High-throughput <p>                 Throughput reaches up to 3 GB/s of 16-bit raw pixel data (a few tomograms/s) on a middle-end GPU node.             </p> Flexible <p>                 Different scan modes as well as configurations of slabs/slices and data processing pipeline are provided.             </p> \u276e \u276f <p>On-demand slab/slice reconstruction for dynamic experiment</p> <p>Rich graphical user interface</p> \u276e \u276f <p>High-resolution 3D reconstruction for static experiment</p> <p>Scalable architecture</p> And more will come Real-time 3D slab reconstruction <p>                 As an enhancement to 2D reconstructed slice, 3D slab will give you localised 3D information in real time.             </p> Segmentation <p>                 Segmentation is essential to better scene understanding. Machine learning will play a pivotal role here.             </p> Rendering materials <p>                 Rendering voxels with real material properties will greatly enhance 3D visualization.             </p> Higher throughput <p>                 We use heterogeneous computing strategy to achieve the highest possible reconstruction throughput.                  Both CPU and GPU algorithms will be further optimised.             </p> Interactive 2D/3D image analysis <p>                 We understand the importance of user experience to online analysis softwares.             </p> Smart data acquisition <p>                 This will generate huge impact on data reduction. Funded by SDSC data science projects                  for large-scale infrastructures.             </p>"},{"location":"data_protocol/","title":"Data protocol","text":""},{"location":"data_protocol/#stream-data-processing","title":"Stream Data Processing","text":"<p>RECASTX was designed to process data streams in near real time. There are two scenarios: receiving data from the data acquisition (DAQ) interface or streaming data from files. </p>"},{"location":"data_protocol/#data-protocol","title":"Data Protocol","text":"<p>The data processing pipeline was originally designed to handle a challenging and unusual scenario, in which the data stream produced by the DAQ is unordered. Therefore, the pipeline relies on the \"frame\" parameter, which should be included in the metadata and sent along with the projections, to sort the incoming data. The frame index is also used to determine when all the projections in a scan have arrived and are ready for a reconstruction. For example, if the number of projections per scan is 500, the reconstruction will start when all the projections with frame number 0 - 499 (500 - 999, 1000 - 1499, etc.) have been received.  Currently, the pipeline cannot handle incomplete scan (e.g. one or more projections are lost for whatever reason).  The unprocessed projections will simply be discarded after all the projections in a later scan have arrived.</p> <p>The pipeline distinguishes three types of image data (dark, flat and projection) by using another parameter \"scan_index\"  (0 for Dark, 1 for Flat and 2 for Projection) which should also be included in the metadata. The shape of the projection is also  required. Please check <code>StdDaqClient::parseData</code> for more details. To summarize, the default (current) DAQ implementation  accepts a ZeroMQ multipart message for each frame. The first part is the metadata in a JSON format like</p> <pre><code>{\n  \"frame\": 100,\n  \"image_attributes\": {\n    \"scan_index\": 0\n  },\n  \"shape\": [512, 512]\n}\n</code></pre> <p>, any additional fields will be ignored. The second part is the bytes of the corresponding image data.</p> <p>If you are also using ZeroMQ, you can easily subclass <code>ZmqDaqClient</code> to make your own DAQ client class. Otherwise,  you can subclass <code>DaqClientInterface</code> if you are using a different messaging library for data streaming.</p>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#when-do-i-need-to-re-collect-dark-and-flat-images","title":"When do I need to re-collect Dark and Flat images?","text":"<p>In the current design, there is no dedicated session for Dark and Flat images collection. In another word, one does not need to click a button to start collecting Dark and Flat images and then stop it. I believe it would need extra coordination and could be error-prone during experiments. </p> <p>To start a reconstruction, one should send Dark and Flat images prior to sending the Projection ones. The original Dark and Flat images will be stored. That is to say, if you change the downsampling factor, you don't need  to re-collect them. The stored Dark and Flat images will be discarded only in one of the following scenarios:</p> <ol> <li> <p>A Dark or Flat image was received and the reciprocal has already been calculated (i.e. at least one Projection image     had been received afterward). The software assumes that you want to re-collect Dark and Flat images.</p> </li> <li> <p>The original image size has been changed.</p> </li> </ol>"},{"location":"faq/#why-the-throughput-on-my-machine-is-below-the-claimed-3-gbs","title":"Why the throughput on my machine is below the claimed 3 GB/s?","text":"<p>See Performance Consideration</p>"},{"location":"faq/#how-can-we-further-improve-the-throughput","title":"How can we further improve the throughput?","text":"<p>Use a GPU node with a decent number (&gt;72) of CPU threads.</p>"},{"location":"faq/#why-do-we-get-the-warning-message-like-received-projection-with-outdated-chunk-index-1234-data-ignored","title":"Why do we get the warning message like \"Received projection with outdated chunk index: 1234, data ignored!\"","text":"<p>As mentioned in Data Protocol, the data pipeline relies on the \"frame\" parameter to sort the incoming projections. If the received frame is believed to be an outdated frame, it will be dropped.</p>"},{"location":"gui/","title":"GUI","text":""},{"location":"gui/#main-control","title":"MAIN CONTROL","text":"<ul> <li>Acquire: Click to only start acquiring the raw projection images and meta data. You can use this feature              to check whether the data streaming is working properly and the projection image is expected.</li> <li>Process: Click to start acquiring and processing data.</li> <li>Stop: Click to stop acquiring and processing data.</li> </ul>"},{"location":"gui/#scan-mode","title":"SCAN MODE","text":"<ul> <li>Mode<ul> <li>Static: The intention is to use it for static experiments (TBD). Currently, the only difference between the Static and Dynamics             modes is that Static mode does not enable double buffering on GPU for sinogram. </li> <li>Dynamic: Reconstruction takes place only after all the projections in a scan have arrived.</li> <li>Continuous: Reconstruction takes place continuously at a given interval.</li> </ul> </li> <li>Update interval: Reconstruction in the Continuous mode will take place each time after receiving the specified number of projections.</li> </ul>"},{"location":"gui/#camera","title":"CAMERA","text":"<ul> <li>Fix camera: Check to disable rotating and zooming the 3D model with mouse.</li> </ul>"},{"location":"gui/#geometry","title":"GEOMETRY","text":"<ul> <li>Column Count: Number of columns of a projection.</li> <li>Row Count: Number of rows of a projection.</li> <li>Angle Count: Number of projections per scan.</li> <li>180 degree / 360 degree: Angle range per scan.</li> <li>Slice Size: Size of the reconstructed slice. Default to Column Count.</li> <li>Volume Size: Size of the reconstructed volume. Default to 128 (for preview).</li> <li>X range: X range of the reconstruction. </li> <li>Y range: Y range of the reconstruction.</li> <li>Z range: Z range of the reconstruction.</li> </ul>"},{"location":"gui/#preprocessing","title":"PREPROCESSING","text":"<ul> <li>Downsample<ul> <li>Col: Down-sampling factor of columns of the raw projection image.</li> <li>Row: Down-sampling factor of rows of the raw projection image.</li> </ul> </li> <li>Minus Log: Uncheck if the data is already linearized.</li> <li>Offset: Offset of the rotation center.</li> <li>Ramp filter: Select the ramp filter applied before FBP reconstruction.</li> </ul>"},{"location":"gui/#projection","title":"PROJECTION","text":"<ul> <li>Display: Uncheck to hide the projection.<ul> <li>Projection ID: The requested projection ID (within a scan). If the ID of the displayed                    projection is different from the requested one. The displayed one will also                    be shown.</li> </ul> </li> <li>Colormap: Colormap for displaying the projection.</li> <li>Auto Levels: Check to enable automatically setting color levels of the displayed objects.<ul> <li>Min: Minimum colormap value.</li> <li>Max: Maximum colormap value.</li> </ul> </li> <li>Keep Aspect Ratio: Uncheck to not keep the aspect ratio of the image. It can                        be used to improve the visualization if images which have large                        aspect ratios.</li> </ul>"},{"location":"gui/#slice-123","title":"SLICE 1/2/3","text":"<ul> <li>Show: Check to display the 2D high-resolution slice.</li> <li>Disable: Check to hide the slice.</li> <li> <p>Offset: Translation of the slice. You can also drag a slice object with mouse.</p> </li> <li> <p>Reset all slices: Click to reset the translations and orientations of all the slices.</p> </li> <li> <p>Colormap: Colormap for rendering the slices.</p> </li> <li>Auto Levels: Check to enable automatically setting color levels of the displayed objects.<ul> <li>Min: Minimum colormap value.</li> <li>Max: Maximum colormap value.</li> </ul> </li> </ul>"},{"location":"gui/#volume","title":"VOLUME","text":"<ul> <li>Preview: Check to use the 3D reconstructed volume as preview.</li> <li>Show: Check to display the 3D reconstructed volume.</li> <li> <p>Disable: Check to disable the reconstruction of the 3D volume. As a result,               there will be no preview when dragging a slice.</p> </li> <li> <p>Quality: Volume rendering quality. 1 is the worst and 5 is the best.</p> </li> <li> <p>Voxel: Check to render the volume as voxels.</p> <ul> <li>Volume Shadow: Check to enable volumetric lighting effect.</li> <li>Threshold: Voxels with intensities smaller than the threshold will not be rendered.</li> <li>View front: Relative position of the front plane of the volume along the view direction.</li> <li>Colormap: Colormap for rendering the volume (shared with the slices).</li> <li>Auto Levels: Check to enable automatically setting color levels of the displayed objects (shared with the slices).<ul> <li>Min: Minimum colormap value (shared with the slices).</li> <li>Max: Maximum colormap value (shared with the slices).</li> </ul> </li> <li>Alphamap:<ul> <li>Ctrl + Left mouse button: Add a new point.</li> <li>d: Delete a point while hovering it (the point will be highlighted).</li> <li>Left mouse button: Press to drag a point vertically. It is not allowed to drag the first point.</li> </ul> </li> </ul> </li> <li> <p>ISO Surface: Check to render the volume as meshes. It is still an experimental feature.</p> <ul> <li>ISO Value: ISO value for finding ISO surfaces.</li> <li>Show Mesh: Render the ISO surfaces as meshes instead of surfaces.</li> <li>Shininess: Shininess of the material.</li> <li>Ambient: Ambient property of the material.</li> <li>Diffuse: Diffuse property of the material.</li> <li>Specular: Specular property of the material.</li> </ul> </li> </ul>"},{"location":"gui/#lighting","title":"LIGHTING","text":"<ul> <li>Show: Check to display the light source object.</li> <li>Position: Position of the point light source.</li> <li>Color: Color of lighting.</li> <li>Ambient: Ambient component of lighting.</li> <li>Diffuse: Diffuse component of lighting.</li> <li>Specular: Specular component of lighting.</li> </ul>"},{"location":"gui/#mouse-and-keyboard","title":"MOUSE AND KEYBOARD","text":"<ul> <li> <p>Reconstructed slices</p> <ul> <li>Select a slice on mouse hover (the selected slice will be highlighted).</li> <li>Move the selected slice along its normal direction by dragging the left mouse button.</li> </ul> </li> <li> <p>Camera</p> <ul> <li>Rotate the model along an axis which is perpendicular to the moving direction by dragging   the middle mouse button or dragging the left mouse button while holding the left Alt.</li> <li>Zoom in/out of the model by scrolling the mouse.</li> <li>w/s: Rotate around the x-axis.</li> <li>a/d: Rotate around the y-axis.</li> <li>space: Reset to perspective view.</li> </ul> </li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>A modern C++ compiler supporting C++17 is required.</p>"},{"location":"installation/#from-source","title":"From source","text":"<p>We recommend using the Anaconda environment.</p>"},{"location":"installation/#installing-the-reconstruction-server","title":"Installing the reconstruction server","text":"<p>On a GPU node (Linux only),</p> <pre><code>git clone --recursive https://github.com/&lt;repo&gt;/recastx.git\ncd recastx\n\nconda env create -f environment-recon.yml\nconda activate recastx-recon\n\nmodule load gcc/12.1.0  # optional\nmkdir build-recon &amp;&amp; cd build-recon\ncmake .. -DCMAKE_PREFIX_PATH=${CONDA_PREFIX:-\"$(dirname $(which conda))/../\"} \\\n         -DCMAKE_CUDA_COMPILER=&lt;path&gt;\nmake -j12 &amp;&amp; make install\n</code></pre>"},{"location":"installation/#installing-the-gui-client","title":"Installing the GUI client","text":""},{"location":"installation/#installing-prerequisites-optional","title":"Installing prerequisites (optional)","text":"<ul> <li>Linux / MaxOS</li> </ul> <p>X11</p> <ul> <li>Windows</li> </ul> <p>TBD</p>"},{"location":"installation/#installing-the-gui-client_1","title":"Installing the GUI client","text":"<ul> <li>Linux / MacOS</li> </ul> <pre><code>git clone --recursive https://github.com/&lt;repo&gt;/recastx.git\ncd recastx\n\nconda env create -f environment-gui.yml\nconda activate recastx-gui\n\nmkdir build-gui &amp;&amp; cd build-gui\ncmake .. -DCMAKE_PREFIX_PATH=${CONDA_PREFIX:-\"$(dirname $(which conda))/../\"} \\\n         -DBUILD_GUI=ON\nmake -j12 &amp;&amp; make install\n</code></pre> <ul> <li>Windows</li> </ul> <p>TBD</p>"},{"location":"installation/#package-managers","title":"Package managers","text":"<p>TBD</p>"},{"location":"performance_consideration/","title":"Performance consideration","text":""},{"location":"performance_consideration/#reconstruction","title":"Reconstruction","text":"<p>Currently, the bottleneck of the data processing pipeline is the preprocessing part, which  is still implemented in CPU. The total number of threads of the current benchmark machine is  only 32. We expect a significant performance boost on a GPU node with a decent number of threads.</p> <p>The 3 GB/s throughput was measured using a projection size of 512 x 512 pixels and 500 projections per scan. The throughput will decrease as the total size of data per scan increases since the performance (in particular  the preprocessing part on CPU) does not scale linearly. If you need a high throughput with large projections  sizes and/or large numbers of projections per scan, it is recommended to down-sample the projections, which can  be configured in the GUI.</p>"},{"location":"performance_consideration/#visualization","title":"Visualization","text":"<p>The data rate in RECASTX is really high not only in terms of the raw  projection images but also in terms of the reconstructed images and volumes. In the default setup, the size of the reconstructed volume is 128 x 128 x 128 pixels, which amounts to 8 MB. Suppose that you would like it to update at 5 Hz, the data rate will be 40 MB/s. It should be noted that the high-resolution slices have not been included. Even though, you may laugh off it because you already have a 10 Gbps network connection between your client and server machines  in your beamline or lab. However, this could be a problem if you are going to  conduct a remote experiment and connect your GUI client to the reconstruct server  via SSH.</p> <p>Even with a 10 Gbps network connection between the client and the sever, the network bandwidth could be a bottleneck if you want to increase the resolution of the reconstructed volume. A high-resolution volume of 1024 x 1024 x 1024 pixels amounts to  4 GB and would be difficult to update at just 1Hz (unless you compress data)  if you don't have a 100 Gbps network connection between the client and the server. Therefore, you should not rule out the possibility of running the GUI client and the reconstruction server on the same machine if it is powerful enough.</p>"},{"location":"run/","title":"Starting pipeline","text":""},{"location":"run/#step-1-starting-the-reconstruction-server","title":"Step 1: Starting the reconstruction server","text":"<pre><code>conda activate recastx-recon\n</code></pre> <p>For a local data source: <pre><code>recastx-recon\n</code></pre></p> <p>For a remote data source (e.g. DAQ node): <pre><code>recastx-recon --daq-address &lt;hostname:port&gt; \n</code></pre></p> <p>For more information, type <pre><code>recastx-recon -h\n</code></pre></p>"},{"location":"run/#step-2-starting-the-gui","title":"Step 2: Starting the GUI","text":"<pre><code>conda activate recastx-gui\n</code></pre> <p>You can specify the reconstruction server <pre><code>recastx-gui --server &lt;hostname:port&gt;\n</code></pre></p> <p>or make use of local port forwarding <pre><code>ssh -L &lt;port&gt;:localhost:&lt;port&gt; &lt;hostname&gt;\nrecastx-gui\n</code></pre></p> <p>You can also start the GUI on a node with NoMachine installed <pre><code>vglrun recastx-gui --server &lt;hostname:port&gt;\n</code></pre></p>"},{"location":"run/#step-3-streaming-the-data","title":"Step 3: Streaming the data","text":""},{"location":"run/#option-1-streaming-data-from-an-area-detector","title":"Option 1: streaming data from an area detector","text":"<p>Contact the corresponding specialists at the facility.</p>"},{"location":"run/#option-2-streaming-data-from-files","title":"Option 2: streaming data from files","text":"<p>We recommend using foamstream. <pre><code>pip install foamstream\n\nfoamstream-tomo --datafile &lt;Your/HDF5 file/path&gt;\n</code></pre></p> <p>Please feel free to use your own file streamer as long as the data protocol is compatible.</p>"},{"location":"tutorial/foam/","title":"Foam (4D)","text":""},{"location":"tutorial/foam/#introduction","title":"Introduction","text":"<p>In this hands-on tutorial, we will take a look at how we can use RECASTX to explore a 4D dataset from a dynamic tomography scan (tomoscopy).</p>"},{"location":"tutorial/foam/#prerequisites","title":"Prerequisites","text":"<p>This tutorial assumes you have already followed our installation guide to install the reconstruction server and the GUI client on a server machine and a client machine, respectively. You will also need to install foamstream on the server machine in order to stream the data from files.</p> <p>We are going to use the Foam dataset offered by TomoBank. Go to the homepage, and then navigate to <code>Datasets/Dynamic/Foam data</code> and download the file <code>dk_MCFG_1_p_s1_.h5</code>.  You can also find the description of the dataset there.</p>"},{"location":"tutorial/foam/#running","title":"Running","text":""},{"location":"tutorial/foam/#streaming-the-data","title":"Streaming the data","text":"<p>Open a terminal and run: <pre><code>foamstream-tomo --datafile &lt;Your/folder/dk_MCFG_1_p_s1_.h5&gt;\n</code></pre> You can find the shapes of the Dark, Flat and Projection images from the output of foamstream.</p>"},{"location":"tutorial/foam/#starting-the-reconstruction-server","title":"Starting the reconstruction server","text":"<p>Open another terminal and run: <pre><code>recastx-recon\n</code></pre></p>"},{"location":"tutorial/foam/#starting-the-gui-client","title":"Starting the GUI client","text":"<p>Open a terminal and run: <pre><code>recastx-gui\n</code></pre></p> <p>Set the following parameters in the GUI:</p> <ul> <li>Set <code>Column Count</code>, <code>Row Count</code> and <code>Angle Count</code> to 2016, 1800 and 300, respectively.</li> </ul> <p>Make sure the <code>SCAN MODE</code> is set to <code>Discrete</code> and click the <code>Process</code> button.</p> <p> </p> Three high-resolution slices <p>Note</p> <p>We turned off the volume reconstruction in order to save the network bandwidth  for visualization. See Performance consideration for more details. Therefore,  there is no preview while dragging the slice.</p>"},{"location":"tutorial/plastic_beads/","title":"Plastic beads (3D)","text":""},{"location":"tutorial/plastic_beads/#introduction","title":"Introduction","text":"<p>In this hands-on tutorial, we will take a look at how we can use RECASTX to explore a 3D dataset from a static tomography scan.</p>"},{"location":"tutorial/plastic_beads/#prerequisites","title":"Prerequisites","text":"<p>This tutorial assumes you have already followed our installation guide  to install the reconstruction server and the GUI client on a server machine and a client  machine, respectively. You will also need to install  foamstream on the server machine in order  to stream the data from files.</p> <p>We are going to use the plastic beeds dataset offered by  TomoBank. Go to the homepage, and then navigate  to <code>Datasets/KBLT</code> and download the file <code>2_plastic_beeds_RGB.h5</code>.  You can also find the description of the dataset there.</p>"},{"location":"tutorial/plastic_beads/#running","title":"Running","text":""},{"location":"tutorial/plastic_beads/#streaming-the-data","title":"Streaming the data","text":"<p>Open a terminal and run: <pre><code>foamstream-tomo --datafile &lt;Your/folder/2_plastic_beeds_RGB.h5&gt; --pdata tomo --pflat flat\n</code></pre> You can find the shapes of the Dark, Flat and Projection images from the output of foamstream.</p>"},{"location":"tutorial/plastic_beads/#starting-the-reconstruction-server","title":"Starting the reconstruction server","text":"<p>Open another terminal and run: <pre><code>recastx-recon\n</code></pre></p> <p>Note</p> <p>The <code>volume-size</code>, which defines the resolution of the \"low-resolution\"  volume, is set to 512 in this case. As a result, the resolution of the  reconstructed volume is indeed high. It should be noted that it thus takes longer time to perform the reconstruction and send the reconstructed volume from the server to the client. Therefore, the default value of <code>volume-size</code> is set to 128 and is recommended to use in dynamic tomography.</p>"},{"location":"tutorial/plastic_beads/#starting-the-gui-client","title":"Starting the GUI client","text":"<p>Open a terminal and run: <pre><code>recastx-gui\n</code></pre></p> <p>Set the following parameters in the GUI:</p> <ul> <li>Set <code>Column Count</code>, <code>Row Count</code> and <code>Angle Count</code> to 130, 400 and 200, respectively.</li> <li>Tick <code>360 degree</code> radio button.</li> <li>Set <code>Volume Size</code> to 512.</li> <li>Set <code>X range</code> and <code>Y range</code> to [-256, 256].</li> </ul> <p>Make sure the <code>SCAN MODE</code> is set to <code>Discrete</code> and click the <code>Process</code> button.</p> <p> </p> Three orthogonal high-resolution slices <p> </p> \"Low-resolution\" volume"}]}